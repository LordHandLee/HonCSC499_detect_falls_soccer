{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOQ8kcMTkSv789DMBOUDOTD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LordHandLee/HonCSC499_detect_falls_soccer/blob/main/Copy_of_ReconstructedModel_02_6_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autokeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5A8xV_47V9u",
        "outputId": "d9d2ae89-40fd-4667-dabe-c2db4c5318c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autokeras\n",
            "  Downloading autokeras-1.1.0-py3-none-any.whl (148 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/148.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autokeras) (23.2)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from autokeras) (2.15.0)\n",
            "Collecting keras-tuner>=1.1.0 (from autokeras)\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-nlp>=0.4.0 (from autokeras)\n",
            "  Downloading keras_nlp-0.7.0-py3-none-any.whl (415 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from autokeras) (1.5.3)\n",
            "Collecting keras-core (from keras-nlp>=0.4.0->autokeras)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (1.23.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (2023.12.25)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (13.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (0.1.8)\n",
            "Collecting tensorflow-text (from keras-nlp>=0.4.0->autokeras)\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner>=1.1.0->autokeras)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->autokeras) (2023.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2024.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp>=0.4.0->autokeras) (4.66.1)\n",
            "Collecting namex (from keras-core->keras-nlp>=0.4.0->autokeras)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp>=0.4.0->autokeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp>=0.4.0->autokeras) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp>=0.4.0->autokeras) (0.16.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp>=0.4.0->autokeras) (0.1.2)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.13.0->tensorflow-text->keras-nlp>=0.4.0->autokeras) (2.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.8.0->autokeras) (3.2.2)\n",
            "Installing collected packages: namex, kt-legacy, keras-tuner, keras-core, tensorflow-text, keras-nlp, autokeras\n",
            "Successfully installed autokeras-1.1.0 keras-core-0.1.7 keras-nlp-0.7.0 keras-tuner-1.4.6 kt-legacy-1.0.5 namex-0.0.7 tensorflow-text-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CBqmToHJd-Nh"
      },
      "outputs": [],
      "source": [
        "import autokeras as ak\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import data,io\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from autokeras.utils import data_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.efficientnet.EfficientNetB1(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224,224,3),\n",
        ")\n"
      ],
      "metadata": {
        "id": "DwPC7GSskMl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457c4481-0ce1-4f38-c565-818cfdd9f8ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
            "27018416/27018416 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@keras.utils.register_keras_serializable()\n",
        "class CastToFloat32(preprocessing.PreprocessingLayer):\n",
        "    def get_config(self):\n",
        "        return super().get_config()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return data_utils.cast_to_float32(inputs)\n",
        "\n",
        "    def adapt(self, data):\n",
        "        return"
      ],
      "metadata": {
        "id": "7z8tFxetlbRb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "w2A-rLp7kpxv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(150,150,3))\n",
        "#x = base_model(inputs, training=False)\n",
        "\n",
        "#x = tf.cast(inputs, tf.int32)\n",
        "x = CastToFloat32()(inputs)\n",
        "\n",
        "#x = CastToFloat32(inputs, shape=(None, 150, 150, 3))\n",
        "\n",
        "x = keras.layers.Normalization(axis=-1, mean=None, variance=None, invert=False)(x)\n",
        "\n",
        "x = keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1, fill_mode='reflect', fill_value=0.0, interpolation='bilinear', seed=None)(x)\n",
        "\n",
        "x = keras.layers.RandomFlip(mode='horizontal', seed=None)(x)\n",
        "\n",
        "x = keras.layers.Resizing(height=224, width=224, interpolation='bilinear', crop_to_aspect_ratio=False)(x)\n",
        "\n",
        "x = base_model(x, training=True)\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D(data_format='channels_last', keepdims=False)(x)\n",
        "\n",
        "x = keras.layers.Dense(1, activation='linear', use_bias=True, kernel_initializer='GlorotUniform', bias_initializer='zeros', kernel_regularizer= None, bias_regularizer= None, activity_regularizer= None, kernel_constraint= None, bias_constraint= None)(x)\n",
        "\n",
        "\n",
        "#dropout?\n",
        "\n",
        "outputs = keras.layers.Activation('sigmoid')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#  random_flip (RandomFlip)    (None, 150, 150, 3)       0\n",
        "\n",
        "#  resizing (Resizing)         (None, 224, 224, 3)       0\n",
        "\n",
        "#  efficientnetb1 (Functional  (None, None, None, 1280   6575239\n",
        "#  )                           )\n",
        "\n",
        "#  global_average_pooling2d (  (None, 1280)              0\n",
        "#  GlobalAveragePooling2D)\n",
        "\n",
        "#  dense (Dense)               (None, 1)                 1281\n",
        "\n",
        "#  classification_head_1 (Ac\n",
        "\n"
      ],
      "metadata": {
        "id": "A9tDTgMnkxuz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMaTYZnsXtfr",
        "outputId": "5ae987b7-1c29-404d-946f-98d915c455fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " cast_to_float32_1 (CastToF  (None, 150, 150, 3)       0         \n",
            " loat32)                                                         \n",
            "                                                                 \n",
            " normalization_2 (Normaliza  (None, 150, 150, 3)       7         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " random_translation_1 (Rand  (None, 150, 150, 3)       0         \n",
            " omTranslation)                                                  \n",
            "                                                                 \n",
            " random_flip_1 (RandomFlip)  (None, 150, 150, 3)       0         \n",
            "                                                                 \n",
            " resizing_1 (Resizing)       (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " efficientnetb1 (Functional  (None, 7, 7, 1280)        6575239   \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1280)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 1281      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6576527 (25.09 MB)\n",
            "Trainable params: 6514465 (24.85 MB)\n",
            "Non-trainable params: 62062 (242.44 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              metrics=[keras.metrics.BinaryAccuracy()])"
      ],
      "metadata": {
        "id": "7cjSG2O4YACk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=30)"
      ],
      "metadata": {
        "id": "ponB3zlPYrV9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "1iyhKOG0Y5o3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmZDg_zyZFF9",
        "outputId": "adf909d8-665b-44dc-f2f3-9fba9fe4c389"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/honor_thesis/image_depo/\""
      ],
      "metadata": {
        "id": "t0vm8LtEZHTQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.3)\n",
        "width = 150\n",
        "height = 150\n",
        "trainDatagen = datagen.flow_from_directory(directory=data_dir, target_size=(width, height),\n",
        "                                           class_mode='binary',\n",
        "                                           batch_size=16,\n",
        "                                           subset='training')\n",
        "valDatagen = datagen.flow_from_directory(directory=data_dir, target_size=(width, height),\n",
        "                                           class_mode='binary',\n",
        "                                           batch_size=16,\n",
        "                                           subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3dnt-6EZSv2",
        "outputId": "5ef0c6d1-3233-42f5-e239-bec6db694894"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 611 images belonging to 2 classes.\n",
            "Found 260 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls \"/content/drive/MyDrive/honor_thesis/image_depo/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwBorLFBaAZo",
        "outputId": "2b051b40-3e24-43f1-8ae1-2bc94ad26c13"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mfallen_images\u001b[0m/  model_autokeras.h5  model_autokeras.keras  \u001b[01;34mstanding_images\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen),\n",
        "                    epochs=500, validation_data = valDatagen,\n",
        "                    validation_steps = len(valDatagen),\n",
        "                    callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGG9jiTeaPO_",
        "outputId": "faec6c5e-737c-47a8-9b56-61b0e4c4adb4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "39/39 [==============================] - 392s 9s/step - loss: 0.9024 - binary_accuracy: 0.5974 - val_loss: 1.1385 - val_binary_accuracy: 0.5769\n",
            "Epoch 2/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.7670 - binary_accuracy: 0.5957 - val_loss: 0.6855 - val_binary_accuracy: 0.7077\n",
            "Epoch 3/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.4442 - binary_accuracy: 0.7971 - val_loss: 0.5780 - val_binary_accuracy: 0.6615\n",
            "Epoch 4/500\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.5861 - binary_accuracy: 0.7152 - val_loss: 0.4276 - val_binary_accuracy: 0.8192\n",
            "Epoch 5/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.3057 - binary_accuracy: 0.8887 - val_loss: 0.3759 - val_binary_accuracy: 0.8423\n",
            "Epoch 6/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.2562 - binary_accuracy: 0.9067 - val_loss: 0.2821 - val_binary_accuracy: 0.8962\n",
            "Epoch 7/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.2310 - binary_accuracy: 0.9264 - val_loss: 0.2765 - val_binary_accuracy: 0.8962\n",
            "Epoch 8/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.1934 - binary_accuracy: 0.9394 - val_loss: 0.2548 - val_binary_accuracy: 0.8769\n",
            "Epoch 9/500\n",
            "39/39 [==============================] - 4s 106ms/step - loss: 0.1579 - binary_accuracy: 0.9362 - val_loss: 0.2245 - val_binary_accuracy: 0.9077\n",
            "Epoch 10/500\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.2625 - binary_accuracy: 0.9002 - val_loss: 0.3418 - val_binary_accuracy: 0.8577\n",
            "Epoch 11/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1721 - binary_accuracy: 0.9394 - val_loss: 0.3458 - val_binary_accuracy: 0.8885\n",
            "Epoch 12/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.2513 - binary_accuracy: 0.9165 - val_loss: 0.2209 - val_binary_accuracy: 0.9269\n",
            "Epoch 13/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1660 - binary_accuracy: 0.9509 - val_loss: 0.2514 - val_binary_accuracy: 0.8962\n",
            "Epoch 14/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1737 - binary_accuracy: 0.9345 - val_loss: 0.2682 - val_binary_accuracy: 0.9269\n",
            "Epoch 15/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1256 - binary_accuracy: 0.9607 - val_loss: 0.2799 - val_binary_accuracy: 0.9077\n",
            "Epoch 16/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1891 - binary_accuracy: 0.9231 - val_loss: 0.2989 - val_binary_accuracy: 0.8731\n",
            "Epoch 17/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.2308 - binary_accuracy: 0.9214 - val_loss: 0.3016 - val_binary_accuracy: 0.9077\n",
            "Epoch 18/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1500 - binary_accuracy: 0.9460 - val_loss: 0.2440 - val_binary_accuracy: 0.9192\n",
            "Epoch 19/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1408 - binary_accuracy: 0.9558 - val_loss: 0.2796 - val_binary_accuracy: 0.9115\n",
            "Epoch 20/500\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.0970 - binary_accuracy: 0.9640 - val_loss: 0.2893 - val_binary_accuracy: 0.9192\n",
            "Epoch 21/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.1980 - binary_accuracy: 0.9182 - val_loss: 0.2856 - val_binary_accuracy: 0.9192\n",
            "Epoch 22/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1602 - binary_accuracy: 0.9509 - val_loss: 0.4649 - val_binary_accuracy: 0.8231\n",
            "Epoch 23/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1942 - binary_accuracy: 0.9231 - val_loss: 0.3670 - val_binary_accuracy: 0.8692\n",
            "Epoch 24/500\n",
            "39/39 [==============================] - 4s 106ms/step - loss: 0.1457 - binary_accuracy: 0.9558 - val_loss: 0.2300 - val_binary_accuracy: 0.9308\n",
            "Epoch 25/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.3368 - binary_accuracy: 0.8871 - val_loss: 0.3220 - val_binary_accuracy: 0.8885\n",
            "Epoch 26/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1545 - binary_accuracy: 0.9378 - val_loss: 0.2670 - val_binary_accuracy: 0.9115\n",
            "Epoch 27/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1543 - binary_accuracy: 0.9574 - val_loss: 0.4289 - val_binary_accuracy: 0.8769\n",
            "Epoch 28/500\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.1329 - binary_accuracy: 0.9476 - val_loss: 0.2763 - val_binary_accuracy: 0.9038\n",
            "Epoch 29/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.0752 - binary_accuracy: 0.9722 - val_loss: 0.3395 - val_binary_accuracy: 0.9077\n",
            "Epoch 30/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.0890 - binary_accuracy: 0.9771 - val_loss: 0.2960 - val_binary_accuracy: 0.9154\n",
            "Epoch 31/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.1086 - binary_accuracy: 0.9640 - val_loss: 0.2298 - val_binary_accuracy: 0.9308\n",
            "Epoch 32/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1112 - binary_accuracy: 0.9656 - val_loss: 0.1987 - val_binary_accuracy: 0.9231\n",
            "Epoch 33/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1358 - binary_accuracy: 0.9476 - val_loss: 0.3011 - val_binary_accuracy: 0.8769\n",
            "Epoch 34/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1487 - binary_accuracy: 0.9444 - val_loss: 0.3837 - val_binary_accuracy: 0.8846\n",
            "Epoch 35/500\n",
            "39/39 [==============================] - 4s 106ms/step - loss: 0.0839 - binary_accuracy: 0.9689 - val_loss: 0.4581 - val_binary_accuracy: 0.8808\n",
            "Epoch 36/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1060 - binary_accuracy: 0.9607 - val_loss: 0.2817 - val_binary_accuracy: 0.8923\n",
            "Epoch 37/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.1232 - binary_accuracy: 0.9640 - val_loss: 0.2026 - val_binary_accuracy: 0.9192\n",
            "Epoch 38/500\n",
            "39/39 [==============================] - 4s 106ms/step - loss: 0.0737 - binary_accuracy: 0.9673 - val_loss: 0.2837 - val_binary_accuracy: 0.9269\n",
            "Epoch 39/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.0911 - binary_accuracy: 0.9673 - val_loss: 0.1931 - val_binary_accuracy: 0.9308\n",
            "Epoch 40/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.0855 - binary_accuracy: 0.9722 - val_loss: 0.2550 - val_binary_accuracy: 0.9154\n",
            "Epoch 41/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.0924 - binary_accuracy: 0.9525 - val_loss: 0.2253 - val_binary_accuracy: 0.9269\n",
            "Epoch 42/500\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.1013 - binary_accuracy: 0.9656 - val_loss: 0.2931 - val_binary_accuracy: 0.9077\n",
            "Epoch 43/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1182 - binary_accuracy: 0.9673 - val_loss: 0.4643 - val_binary_accuracy: 0.8654\n",
            "Epoch 44/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.1010 - binary_accuracy: 0.9656 - val_loss: 0.3900 - val_binary_accuracy: 0.9038\n",
            "Epoch 45/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.1318 - binary_accuracy: 0.9493 - val_loss: 0.3134 - val_binary_accuracy: 0.8923\n",
            "Epoch 46/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.0947 - binary_accuracy: 0.9673 - val_loss: 0.3112 - val_binary_accuracy: 0.9038\n",
            "Epoch 47/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.0458 - binary_accuracy: 0.9836 - val_loss: 0.2377 - val_binary_accuracy: 0.9269\n",
            "Epoch 48/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.0717 - binary_accuracy: 0.9738 - val_loss: 0.2701 - val_binary_accuracy: 0.9077\n",
            "Epoch 49/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1434 - binary_accuracy: 0.9476 - val_loss: 0.3059 - val_binary_accuracy: 0.8923\n",
            "Epoch 50/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1071 - binary_accuracy: 0.9591 - val_loss: 0.3086 - val_binary_accuracy: 0.9038\n",
            "Epoch 51/500\n",
            "39/39 [==============================] - 4s 102ms/step - loss: 0.0942 - binary_accuracy: 0.9705 - val_loss: 0.5357 - val_binary_accuracy: 0.8231\n",
            "Epoch 52/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.2424 - binary_accuracy: 0.9182 - val_loss: 0.2675 - val_binary_accuracy: 0.9269\n",
            "Epoch 53/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1015 - binary_accuracy: 0.9624 - val_loss: 0.3764 - val_binary_accuracy: 0.8962\n",
            "Epoch 54/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1000 - binary_accuracy: 0.9624 - val_loss: 0.3166 - val_binary_accuracy: 0.9154\n",
            "Epoch 55/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.0871 - binary_accuracy: 0.9624 - val_loss: 0.2013 - val_binary_accuracy: 0.9500\n",
            "Epoch 56/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1688 - binary_accuracy: 0.9362 - val_loss: 0.2442 - val_binary_accuracy: 0.9154\n",
            "Epoch 57/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.0793 - binary_accuracy: 0.9738 - val_loss: 0.3457 - val_binary_accuracy: 0.8962\n",
            "Epoch 58/500\n",
            "39/39 [==============================] - 4s 106ms/step - loss: 0.1132 - binary_accuracy: 0.9673 - val_loss: 0.2043 - val_binary_accuracy: 0.9231\n",
            "Epoch 59/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.0818 - binary_accuracy: 0.9689 - val_loss: 0.3121 - val_binary_accuracy: 0.9192\n",
            "Epoch 60/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.0670 - binary_accuracy: 0.9705 - val_loss: 0.2857 - val_binary_accuracy: 0.9154\n",
            "Epoch 61/500\n",
            "39/39 [==============================] - 4s 104ms/step - loss: 0.1550 - binary_accuracy: 0.9525 - val_loss: 0.2780 - val_binary_accuracy: 0.9077\n",
            "Epoch 62/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1224 - binary_accuracy: 0.9558 - val_loss: 0.2873 - val_binary_accuracy: 0.9077\n",
            "Epoch 63/500\n",
            "39/39 [==============================] - 4s 101ms/step - loss: 0.1235 - binary_accuracy: 0.9525 - val_loss: 0.2364 - val_binary_accuracy: 0.9231\n",
            "Epoch 64/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.0871 - binary_accuracy: 0.9689 - val_loss: 0.2520 - val_binary_accuracy: 0.9154\n",
            "Epoch 65/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.1074 - binary_accuracy: 0.9640 - val_loss: 0.2225 - val_binary_accuracy: 0.9231\n",
            "Epoch 66/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1634 - binary_accuracy: 0.9509 - val_loss: 0.3024 - val_binary_accuracy: 0.9115\n",
            "Epoch 67/500\n",
            "39/39 [==============================] - 4s 105ms/step - loss: 0.1386 - binary_accuracy: 0.9493 - val_loss: 0.3253 - val_binary_accuracy: 0.8962\n",
            "Epoch 68/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.0915 - binary_accuracy: 0.9624 - val_loss: 0.2155 - val_binary_accuracy: 0.9346\n",
            "Epoch 69/500\n",
            "39/39 [==============================] - 4s 103ms/step - loss: 0.0678 - binary_accuracy: 0.9804 - val_loss: 0.2433 - val_binary_accuracy: 0.9192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(trainDatagen, steps_per_epoch = len(trainDatagen),\n",
        "                    epochs=500, validation_data = valDatagen,\n",
        "                    validation_steps = len(valDatagen),\n",
        "                    callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n11oSu42bmTu",
        "outputId": "b6d772c2-2b7f-4337-8845-faa0cdc58820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "39/39 [==============================] - 63s 152ms/step - loss: 0.9531 - binary_accuracy: 0.5123 - val_loss: 0.7326 - val_binary_accuracy: 0.5000\n",
            "Epoch 2/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.7088 - binary_accuracy: 0.5548 - val_loss: 0.7354 - val_binary_accuracy: 0.4962\n",
            "Epoch 3/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.7076 - binary_accuracy: 0.5417 - val_loss: 0.7012 - val_binary_accuracy: 0.5038\n",
            "Epoch 4/500\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.7132 - binary_accuracy: 0.5106 - val_loss: 0.6888 - val_binary_accuracy: 0.5462\n",
            "Epoch 5/500\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.6692 - binary_accuracy: 0.5679 - val_loss: 0.7334 - val_binary_accuracy: 0.5538\n",
            "Epoch 6/500\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.6771 - binary_accuracy: 0.5646 - val_loss: 0.6916 - val_binary_accuracy: 0.5538\n",
            "Epoch 7/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.6924 - binary_accuracy: 0.5777 - val_loss: 0.6878 - val_binary_accuracy: 0.5846\n",
            "Epoch 8/500\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.6867 - binary_accuracy: 0.5581 - val_loss: 0.7145 - val_binary_accuracy: 0.5731\n",
            "Epoch 9/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.6551 - binary_accuracy: 0.5974 - val_loss: 0.7229 - val_binary_accuracy: 0.5423\n",
            "Epoch 10/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.6707 - binary_accuracy: 0.5925 - val_loss: 0.6896 - val_binary_accuracy: 0.5000\n",
            "Epoch 11/500\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.6669 - binary_accuracy: 0.5679 - val_loss: 0.6617 - val_binary_accuracy: 0.6500\n",
            "Epoch 12/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.6398 - binary_accuracy: 0.6252 - val_loss: 0.6469 - val_binary_accuracy: 0.6500\n",
            "Epoch 13/500\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.6230 - binary_accuracy: 0.6514 - val_loss: 0.6812 - val_binary_accuracy: 0.6115\n",
            "Epoch 14/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.6091 - binary_accuracy: 0.6399 - val_loss: 0.6923 - val_binary_accuracy: 0.6077\n",
            "Epoch 15/500\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.6298 - binary_accuracy: 0.6432 - val_loss: 0.6523 - val_binary_accuracy: 0.6346\n",
            "Epoch 16/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5822 - binary_accuracy: 0.6939 - val_loss: 0.6507 - val_binary_accuracy: 0.5923\n",
            "Epoch 17/500\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.5967 - binary_accuracy: 0.6743 - val_loss: 0.6909 - val_binary_accuracy: 0.6077\n",
            "Epoch 18/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.6264 - binary_accuracy: 0.6727 - val_loss: 0.6152 - val_binary_accuracy: 0.6654\n",
            "Epoch 19/500\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.5730 - binary_accuracy: 0.6825 - val_loss: 0.6324 - val_binary_accuracy: 0.6692\n",
            "Epoch 20/500\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.5700 - binary_accuracy: 0.6989 - val_loss: 0.6568 - val_binary_accuracy: 0.6923\n",
            "Epoch 21/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5760 - binary_accuracy: 0.6710 - val_loss: 0.6389 - val_binary_accuracy: 0.6077\n",
            "Epoch 22/500\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.5569 - binary_accuracy: 0.6907 - val_loss: 0.6037 - val_binary_accuracy: 0.6577\n",
            "Epoch 23/500\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.5382 - binary_accuracy: 0.7185 - val_loss: 0.6692 - val_binary_accuracy: 0.6423\n",
            "Epoch 24/500\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5750 - binary_accuracy: 0.6776 - val_loss: 0.6489 - val_binary_accuracy: 0.6308\n",
            "Epoch 25/500\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.5696 - binary_accuracy: 0.6809 - val_loss: 0.6203 - val_binary_accuracy: 0.6308\n",
            "Epoch 26/500\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.5756 - binary_accuracy: 0.6956 - val_loss: 0.6094 - val_binary_accuracy: 0.6385\n",
            "Epoch 27/500\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.5609 - binary_accuracy: 0.6907 - val_loss: 0.6809 - val_binary_accuracy: 0.6577\n",
            "Epoch 28/500\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.5637 - binary_accuracy: 0.6972 - val_loss: 0.5866 - val_binary_accuracy: 0.6808\n",
            "Epoch 29/500\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5415 - binary_accuracy: 0.7119 - val_loss: 0.7053 - val_binary_accuracy: 0.6154\n",
            "Epoch 30/500\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.5410 - binary_accuracy: 0.6874 - val_loss: 0.6401 - val_binary_accuracy: 0.6615\n",
            "Epoch 31/500\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5522 - binary_accuracy: 0.6825 - val_loss: 0.6426 - val_binary_accuracy: 0.6731\n",
            "Epoch 32/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5534 - binary_accuracy: 0.7185 - val_loss: 0.6259 - val_binary_accuracy: 0.6885\n",
            "Epoch 33/500\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5425 - binary_accuracy: 0.7119 - val_loss: 0.6339 - val_binary_accuracy: 0.6731\n",
            "Epoch 34/500\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5406 - binary_accuracy: 0.7250 - val_loss: 0.6448 - val_binary_accuracy: 0.6346\n",
            "Epoch 35/500\n",
            "39/39 [==============================] - 4s 92ms/step - loss: 0.5449 - binary_accuracy: 0.7005 - val_loss: 0.6105 - val_binary_accuracy: 0.6692\n",
            "Epoch 36/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5334 - binary_accuracy: 0.6874 - val_loss: 0.6225 - val_binary_accuracy: 0.6769\n",
            "Epoch 37/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5508 - binary_accuracy: 0.6874 - val_loss: 0.6990 - val_binary_accuracy: 0.6346\n",
            "Epoch 38/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5156 - binary_accuracy: 0.7218 - val_loss: 0.6260 - val_binary_accuracy: 0.6077\n",
            "Epoch 39/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5231 - binary_accuracy: 0.7169 - val_loss: 0.6417 - val_binary_accuracy: 0.7077\n",
            "Epoch 40/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5205 - binary_accuracy: 0.7201 - val_loss: 0.5982 - val_binary_accuracy: 0.6846\n",
            "Epoch 41/500\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.5073 - binary_accuracy: 0.7300 - val_loss: 0.6998 - val_binary_accuracy: 0.6462\n",
            "Epoch 42/500\n",
            "39/39 [==============================] - 3s 89ms/step - loss: 0.4983 - binary_accuracy: 0.7283 - val_loss: 0.6683 - val_binary_accuracy: 0.6962\n",
            "Epoch 43/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5338 - binary_accuracy: 0.7218 - val_loss: 0.6059 - val_binary_accuracy: 0.6885\n",
            "Epoch 44/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5034 - binary_accuracy: 0.7414 - val_loss: 0.6628 - val_binary_accuracy: 0.6654\n",
            "Epoch 45/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5034 - binary_accuracy: 0.7300 - val_loss: 0.6215 - val_binary_accuracy: 0.6846\n",
            "Epoch 46/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5159 - binary_accuracy: 0.7087 - val_loss: 0.6571 - val_binary_accuracy: 0.6615\n",
            "Epoch 47/500\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.5136 - binary_accuracy: 0.7070 - val_loss: 0.6314 - val_binary_accuracy: 0.6577\n",
            "Epoch 48/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.5229 - binary_accuracy: 0.7250 - val_loss: 0.6014 - val_binary_accuracy: 0.7038\n",
            "Epoch 49/500\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.5082 - binary_accuracy: 0.7332 - val_loss: 0.6383 - val_binary_accuracy: 0.6500\n",
            "Epoch 50/500\n",
            "39/39 [==============================] - 4s 93ms/step - loss: 0.4961 - binary_accuracy: 0.7430 - val_loss: 0.6397 - val_binary_accuracy: 0.6269\n",
            "Epoch 51/500\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.5108 - binary_accuracy: 0.7185 - val_loss: 0.6574 - val_binary_accuracy: 0.6538\n",
            "Epoch 52/500\n",
            "39/39 [==============================] - 4s 90ms/step - loss: 0.4941 - binary_accuracy: 0.7332 - val_loss: 0.6351 - val_binary_accuracy: 0.6308\n",
            "Epoch 53/500\n",
            "39/39 [==============================] - 4s 91ms/step - loss: 0.4770 - binary_accuracy: 0.7267 - val_loss: 0.6667 - val_binary_accuracy: 0.6615\n",
            "Epoch 54/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5319 - binary_accuracy: 0.7300 - val_loss: 0.6589 - val_binary_accuracy: 0.6385\n",
            "Epoch 55/500\n",
            "39/39 [==============================] - 3s 87ms/step - loss: 0.5257 - binary_accuracy: 0.7070 - val_loss: 0.6702 - val_binary_accuracy: 0.6423\n",
            "Epoch 56/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5176 - binary_accuracy: 0.7267 - val_loss: 0.6193 - val_binary_accuracy: 0.6385\n",
            "Epoch 57/500\n",
            "39/39 [==============================] - 4s 89ms/step - loss: 0.5234 - binary_accuracy: 0.7332 - val_loss: 0.6475 - val_binary_accuracy: 0.6615\n",
            "Epoch 58/500\n",
            "39/39 [==============================] - 3s 88ms/step - loss: 0.4968 - binary_accuracy: 0.7480 - val_loss: 0.6012 - val_binary_accuracy: 0.6615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XsQ999uQckXA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}